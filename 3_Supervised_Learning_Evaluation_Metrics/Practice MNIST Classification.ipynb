{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Z6shD1SL8w_"
   },
   "source": [
    "<img src=\"../figs/holberton_logo.png\" alt=\"logo\" width=\"500\"/>\n",
    "\n",
    "# Classification of Hand Written Digits\n",
    "\n",
    "## 0. Image Classification Task\n",
    "\n",
    "Image classification is a fundamental task in machine learning and computer vision where the goal is to **assign a label to an image from a predefined set of categories**. This task involves analyzing the content of an image and identifying the objects or patterns present in it.\n",
    "\n",
    "\n",
    "### Importance of Image Classification:\n",
    "\n",
    "- **Medical Diagnosis**: Helps in diagnosing diseases by classifying medical images, such as X-rays and MRI scans, enabling early detection and treatment.\n",
    "\n",
    "- **Security and Surveillance**: Enhances security systems by identifying objects, activities, or individuals in surveillance footage.\n",
    "\n",
    "- **Retail and E-commerce**: Improves customer experience by automatically tagging products, enabling visual search, and providing personalized recommendations.\n",
    "\n",
    "- **Self-Driving Cars**: Essential for autonomous vehicles to recognize and respond to various objects on the road, such as traffic signs, pedestrians, and other vehicles.\n",
    "\n",
    "This example shows how to build a feed forward neural network that can be used to recognize images of hand-written digits, from 0-9.\n",
    "\n",
    "### Basic Image Classification through the MNIST dataset\n",
    "\n",
    "The MNIST dataset is a widely used benchmark in the field of machine learning and computer vision, consisting of 70,000 grayscale images of handwritten digits (0-9), each sized 28x28 pixels. It includes 60,000 training images and 10,000 testing images. MNIST serves as a standard for evaluating and comparing the performance of various neural network architectures due to its simplicity, well-structured format, and the broad availability of pre-existing results for reference\n",
    "\n",
    "### Workflow\n",
    "\n",
    "<img src=\"../figs/3-supervised/pipeline.png\" alt=\"logo\" width=\"900\"/>\n",
    "\n",
    "\n",
    "Our workflow will consist of the following steps\n",
    "- import libraries needed to compile and train the neural network and visualize data\n",
    "- get the MNIST dataset of handwritten digits\n",
    "- preprocess the data\n",
    "- split the dataset into data used for training and testing\n",
    "- build the neural network\n",
    "- train the neural network\n",
    "- test the neural network by evaluating its performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upbDs27BM_oF"
   },
   "source": [
    "## Import libraries\n",
    "- tensorflow\n",
    "- keras\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQXspm48M0Q0"
   },
   "outputs": [],
   "source": [
    "# Let's import the libraries we'll need\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rtIhF0ZNJ2U"
   },
   "source": [
    "## Load the MNIST dataset\n",
    "- the dataset is part of keras\n",
    "- store the data in tuples for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVSNpDLJNP7O",
    "outputId": "aa4c866d-52f0-4d4a-fcb7-48eb8ca8bf6d"
   },
   "outputs": [],
   "source": [
    "# Now, let's load the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpChqoPUNapG"
   },
   "source": [
    "## Preprocess the data\n",
    "- the color pixel value of each image will be represented as a float from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24xRNwvlNj7p"
   },
   "outputs": [],
   "source": [
    "# Next, we'll preprocess the data by scaling it to a range of 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nzxb4piNmCS"
   },
   "source": [
    "## Split the dataset in train, validation and test dataset\n",
    "- validation will contain the first 5000 images\n",
    "- train will contain all images, but the first 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeX1m04qNxlv"
   },
   "outputs": [],
   "source": [
    "# now, we will split the dataset in train, validation and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0MFxOOlN1DG"
   },
   "source": [
    "## Build Neural Network \n",
    "- Define a sequential model containing\n",
    "  - a flatten layer receiving inputs in the shape of 28 x 28 pixels\n",
    "  - a Dense layer of 128 neurons, using the `relu` activation function\n",
    "  - a Dense layer of 10 neurons using the `softmax` activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3UDlbDMOHX0"
   },
   "outputs": [],
   "source": [
    "# Now, let's define our neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsWa5wpEOJJb"
   },
   "source": [
    "## Compile the model\n",
    "- use the `adam` optimizer\n",
    "- use the `sparse categorical cross entropy` loss function\n",
    "- use `accuracy` as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ2xSoaSOUk1"
   },
   "outputs": [],
   "source": [
    "# Now, let's compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRrolM9iOWgo"
   },
   "source": [
    "## Train the model\n",
    "- use method `fit` to train the model for 5 epochs\n",
    "- use also the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBvPQHZwOfKd",
    "outputId": "07965b0c-e407-437e-f5e4-e5bfcdc5a419"
   },
   "outputs": [],
   "source": [
    "# Now, let's train the model, and also save the history of training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXujCeLfOp85"
   },
   "source": [
    "## Evaluate the model\n",
    "- evaluate the model on the test set\n",
    "- store the test loss and the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyPS4ausOzBF",
    "outputId": "64a0363b-beca-491c-ce7c-d00787ab41e3"
   },
   "outputs": [],
   "source": [
    "# Now, let's evaluate the model on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJo9gNOmO2Tq"
   },
   "source": [
    "## Visualize data\n",
    "- use `matplotlib.pyplot` to plot the training and validation accuracy and loss\n",
    "- display the number of epochs and the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "A3vtLQWoPC-i",
    "outputId": "45a625bc-67da-4e18-bb48-26969a4dc849"
   },
   "outputs": [],
   "source": [
    "# Now, let's plot the training and validation accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for classification metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Make predictions on the test set\n",
    "\n",
    "\n",
    "# Calculate precision, recall, and f1 score\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "\n",
    "# Compute the confusion matrix\n",
    "\n",
    "# Visualize the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbEOCZu9PF9Y"
   },
   "source": [
    "## Visualize the classification of several images\n",
    "- select 20 images at random\n",
    "- visualize the images alongside their labels in a grid-like plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "4dnGpQviu7gS",
    "outputId": "c6b7a11a-f1f1-4c79-c60f-c83943fffaba"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_indices = np.random.randint(0, len(x_train), 20)\n",
    "random_images = x_train[random_indices]\n",
    "random_labels = y_train[random_indices]\n",
    "\n",
    "fix, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "  ax.imshow(random_images[i], cmap='gray')\n",
    "  ax.axis(\"off\")\n",
    "  ax.set_title(str(random_labels[i]))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tk4oazStPWq9"
   },
   "source": [
    "## Congrats on building your (first) neural network"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
