{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd98120",
   "metadata": {},
   "source": [
    "<img src=\"../figs/holberton_logo.png\" alt=\"logo\" width=\"500\"/>\n",
    "\n",
    "# Price Prediction Analysis\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "In this project, our primary goal is to **explore the California housing dataset and analyze various factors such as location, number of rooms, income levels, and housing trends**. We will then **develop a machine learning model to predict housing prices**. This analysis and model will provide valuable insights for home buyers, sellers, and real estate investors, aiding them in making informed decisions in the dynamic California housing market.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### Data Collection and Understanding:\n",
    "\n",
    "- Obtain the California housing dataset, understand its features, and gain insights into the target variable (housing prices).\n",
    "\n",
    "\n",
    "### Data Preprocessing:\n",
    "\n",
    "- Handle missing values, if any.\n",
    "- Normalize or standardize numerical features to ensure they have similar scales.\n",
    "- Encode categorical variables if needed.\n",
    "\n",
    "\n",
    "### Selecting Features and Preparing Data \n",
    "\n",
    "- Select relevant features that could affect housing prices.\n",
    "- Divide the dataset into training and testing sets to evaluate the model's performance.\n",
    "\n",
    "### Model Training:\n",
    "\n",
    "- Implement traditional machine learning models using libraries like `scikit-learn`\n",
    "- Train the model on the training dataset.\n",
    "\n",
    "### Model Evaluation:\n",
    "\n",
    "- Evaluate the model's performance using metrics like Mean Squared Error (MSE) and R-squared.\n",
    "- Analyze the residuals to ensure the model assumptions hold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4f9d6",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Exploration\n",
    "\n",
    "To initiate the development of a price prediction model for California housing using linear regression, we begin by obtaining the dataset and comprehending its attributes, focusing on the target variable, housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5419b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "from   sklearn.datasets  import fetch_california_housing\n",
    "\n",
    "# Load the California housing dataset\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "print(california_housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9236f6",
   "metadata": {},
   "source": [
    "### Convert the Dataset to a DataFrame\n",
    "\n",
    "We convert the California housing dataset into a pandas `DataFrame` for easier data manipulation and analysis. To achieve that, we assign the feature data to columns based on their names and adds a '`target`' column representing housing prices. We print the first few rows of the DataFrame to provide an initial look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579b5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a DataFrame\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782f4eb",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "The goal of Exploratory Data Analysis (EDA) in the California housing dataset is to **understand the underlying patterns, relationships, and distributions of the data**. \n",
    "\n",
    "EDA involves **summarizing the main characteristics of the dataset** using visualizations and statistical techniques. This process helps in *identifying any anomalies, outliers, or missing values* and provides insights into the relationships between different features and the target variable. \n",
    "\n",
    "By conducting EDA, we aim to **gain a comprehensive understanding of the data**, which will inform the subsequent steps of data preprocessing, feature engineering, and model building for predicting housing prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8776a2e",
   "metadata": {},
   "source": [
    "#### Explore Relationships in the Dataset\n",
    "\n",
    "This plot provides a pairwise relationship between different features in the dataset. It's useful for identifying potential correlations and patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fd7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae964f7",
   "metadata": {},
   "source": [
    "#### Correlation heatmap\n",
    "\n",
    "The goal of creating a correlation heatmap is to **visualize the relationships between different features in the California housing dataset**. This helps in identifying **which features are strongly correlated with each other** and **with the target variable**, aiding in feature selection and engineering for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d99d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524955c4",
   "metadata": {},
   "source": [
    "From the correlation heatmap results, the key takeaways are:\n",
    "\n",
    "- **Median Income (MedInc)** has a strong positive correlation with the target (0.688), indicating it is an important predictor of housing prices.\n",
    "- **House Age (HouseAge)** shows a mild positive correlation with the target (0.106), suggesting it has some influence on housing prices.\n",
    "- **Average Rooms (AveRooms)** also has a mild positive correlation with the target (0.152), indicating more rooms may slightly increase housing prices.\n",
    "- **Latitude** shows a moderate negative correlation with the target (-0.144), indicating that houses further north might be less expensive.\n",
    "- Other features such as `AveBedrms`, `Population` and `AveOccup` have weak correlations with the target, implying they are less significant predictors of housing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408e958",
   "metadata": {},
   "source": [
    "#### Histogram of numerical features\n",
    "\n",
    "The histogram provides a visual representation of the distribution of various numerical features in the California housing dataset. \n",
    "\n",
    "By examining these histograms, we can gain insights into the central tendencies, spread, and shape of the distributions for features such as median income, house age, average rooms, and more. \n",
    "\n",
    "This visualization helps identify any skewness, outliers, or unusual patterns within the data. \n",
    "\n",
    "For instance, we can observe the distribution of house ages or income levels across different ranges, which is essential for understanding the underlying characteristics of the dataset before proceeding with further analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c292ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histograms with grid lines and custom bin colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15522eb3",
   "metadata": {},
   "source": [
    "#### Boxplot of target variable\n",
    "\n",
    "Plot a boxplot of the target variable (housing prices) to identify outliers and understand its distribution.\n",
    "\n",
    "The boxplot highlights the median price, the interquartile range, and any potential outliers, allowing us to quickly assess the spread and skewness of the housing prices in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3834fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f34082",
   "metadata": {},
   "source": [
    "##### Findings:\n",
    "- The boxplot indicates a significant number of properties at the upper limit of the target variable, suggesting a cap in the data recording process or truly high-value properties.\n",
    "- Analyzing these outliers helps in understanding the characteristics of these high-value properties, which can be crucial for real estate analysis and predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02cc2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03a019",
   "metadata": {},
   "source": [
    "#### Scatterplot of Median Income vs. Target\n",
    "\n",
    "The scatterplot of median income versus the target variable (housing price) provides valuable insights into the relationship between these two features. By plotting median income on the x-axis and housing prices on the y-axis, we can **visually assess how income levels influence housing prices**. \n",
    "\n",
    "This scatterplot **reveals a positive correlation**, suggesting that higher median incomes are generally associated with higher housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61933bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96922b6",
   "metadata": {},
   "source": [
    "#### Plotting housing prices versus the geographical location\n",
    "\n",
    "The goal of this scatterplot is to **visualize the geographic distribution of housing prices across California**. By plotting longitude on the `x-axis` and latitude on the `y-axis`, we map housing prices spatially. \n",
    "\n",
    "**The color of each point represents the housing price**, with the color bar indicating the price scale. \n",
    "\n",
    "This visualization helps identify regional price variations and potential clusters of high or low housing prices, providing insights into how location affects real estate values within the state. Such spatial analysis is crucial for understanding local market dynamics and guiding location-based investment decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62d2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e110c",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "### Check for Missing Values\n",
    "\n",
    "We first check for missing values in the California housing dataset by using the `isnull()` method and summing all values that are `null` to get the total. As we can observe the dataset does not contain any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6b63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9938d001",
   "metadata": {},
   "source": [
    "### Normalize (Standardize) Numerical Features\n",
    "\n",
    "The goal of this code is to **standardize the numerical features in the California housing dataset**. \n",
    "\n",
    "Standardization involves scaling the features **to have a mean of `0` and a standard deviation of `1`**. This preprocessing step ensures that all numerical features contribute equally to the model, avoiding biases caused by different scales. \n",
    "\n",
    "By applying the `StandardScaler`, we prepare the data for better performance and convergence of machine learning algorithms, particularly those sensitive to feature scaling, like linear regression or gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d4c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed9041",
   "metadata": {},
   "source": [
    "### 3. Selecting Features and Preparing Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03999b",
   "metadata": {},
   "source": [
    "### Split the Dataset into Training and Testing Set\n",
    "\n",
    "In this step, we prepare our dataset for training and evaluating machine learning models by performing the following actions:\n",
    "\n",
    "#### Selecting Features and Target Variable:\n",
    "\n",
    "- `X = california_df.drop('target', axis=1)` selects all columns except the '`target`' column to be the features (`X`).\n",
    "- `y = california_df['target']` selects the 'target' column to be the target variable (y), which represents housing prices.\n",
    "\n",
    "#### Splitting the Dataset:\n",
    "\n",
    "- We use `train_test_split` from `sklearn.model_selection` to divide the dataset into training and testing sets. This is crucial for evaluating the model's performance on unseen data.\n",
    "- `test_size=0.2` indicates that `20%` of the data will be used for testing, while `80%` will be used for training.\n",
    "- `random_state=42` ensures reproducibility by controlling the random shuffling applied before the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27f2be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0ac3e",
   "metadata": {},
   "source": [
    "## 4. Model Training:\n",
    "\n",
    "### 4.1. Random Forest Regressor\n",
    "\n",
    "In this section, we will train a machine learning model using the **Random Forest Regressor**. The Random Forest algorithm is an **ensemble learning method** that is widely used for regression and classification tasks. \n",
    "\n",
    "#### Motivation Behind Using Random Forest Regressor\n",
    "- **Handling Non-linearity**: Random Forest is capable of capturing non-linear relationships between the features and the target variable, which is important for complex datasets like housing prices.\n",
    "- **Feature Importance**: It provides insights into the importance of various features in predicting the target variable, helping us understand the most influential factors.\n",
    "- **Robustness**: The algorithm is robust to overfitting, especially when dealing with a large number of features and data points.\n",
    "\n",
    "#### How the Random Forest Algorithm Works\n",
    "- **Ensemble of Decision Trees**: Random Forest builds multiple decision trees during training and merges their results to improve accuracy and control overfitting.\n",
    "- **Bootstrap Aggregation (Bagging)**: It creates multiple subsets of the training data using sampling with replacement and trains a decision tree on each subset.\n",
    "- **Random Feature Selection**: At each split in the decision tree, a random subset of features is considered, promoting diversity among the trees.\n",
    "- **Averaging Predictions**: For regression tasks, the final prediction is obtained by averaging the predictions from all individual trees.\n",
    "\n",
    "\n",
    "<img src=\"../figs/2-dataprocess/randforest.png\" alt=\"logo\" width=\"700\"/>\n",
    "\n",
    "\n",
    "\n",
    "#### Suitability for the California Housing Dataset\n",
    "- **Complex Relationships**: Housing prices can be influenced by various factors like median income, house age, and geographical location. Random Forest can model these complex interactions effectively.\n",
    "- **Feature Importance**: The algorithm can help identify which features are most predictive of housing prices, offering valuable insights for further analysis.\n",
    "- **Outliers and Noise**: Random Forest is robust to outliers and noise in the data, which is beneficial given the potential outliers we observed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e4d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4013b21",
   "metadata": {},
   "source": [
    "### 4.2 Gradient Boosting Regressor\n",
    "\n",
    "In this section, we will train a machine learning model using the **Gradient Boosting Regressor**. Gradient Boosting is an **ensemble learning technique** that builds models sequentially to correct the errors of the previous models\n",
    "\n",
    "#### Motivation Behind Using Gradient Boosting Regressor\n",
    "- **High Predictive Power**: Gradient Boosting is known for its high accuracy and ability to capture complex patterns in the data.\n",
    "- **Reduction of Bias**: By iteratively improving on the errors of previous models, Gradient Boosting reduces both bias and variance.\n",
    "- **Customizable**: The algorithm offers various hyperparameters that can be tuned to optimize performance for specific datasets.\n",
    "\n",
    "<img src=\"../figs/2-dataprocess/gradientboosting.png\" alt=\"logo\" width=\"700\"/>\n",
    "\n",
    "\n",
    "#### How the Gradient Boosting Algorithm Works\n",
    "- **Sequential Model Building**: Gradient Boosting builds models in a sequential manner, where each new model corrects the errors of the previous ones.\n",
    "- **Weighted Averaging**: It uses a weighted sum of predictions from all models to make the final prediction.\n",
    "- **Loss Function Minimization**: The algorithm focuses on minimizing a specified loss function (e.g., mean squared error) by taking steps in the direction of the negative gradient.\n",
    "- **Learning Rate**: A parameter that controls the contribution of each model to the final prediction, allowing for fine-tuning of the algorithm’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6796332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c35ef",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "In this phase, we will evaluate the performance of our trained models using specific error metrics. The metrics we will use are `Mean Squared Error (MSE)` and the `Coefficient of Determination` ($R^2$ score). These metrics are chosen because they provide a comprehensive understanding of the model’s performance, particularly in the context of regression tasks like predicting housing prices.\n",
    "\n",
    "### 5.1. Mean Squared Error (MSE)\n",
    "\n",
    "- **Definition**: MSE is the average of the squares of the differences between the actual and predicted values. It is calculated as\n",
    "\n",
    "$$\n",
    "\\displaystyle MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "where $y_i$ are the actual values,  $\\hat{y}_i$ are the predicted values and $n$ is the number of observations.\n",
    "\n",
    "- **Relevance**: MSE is particularly useful because it penalizes larger errors more than smaller ones, making it sensitive to outliers. This characteristic is important in the housing market, where large prediction errors can have significant financial implications.\n",
    "\n",
    "- **Interpretation**: A lower MSE indicates better model performance, with an MSE of 0 meaning perfect predictions.\n",
    "\n",
    "### 5.2. Model Evaluation: Coefficient of Determination (R²)\n",
    "\n",
    "The Coefficient of Determination, commonly known as R², is a crucial metric used to evaluate the performance of regression models. It provides an indication of how well the model's predictions match the actual data. The R² value ranges from 0 to 1, where a value closer to 1 indicates a better fit. An R² value of 1 signifies that the model perfectly predicts the target variable, while an R² value of 0 indicates that the model fails to explain any of the variability in the target variable.\n",
    "\n",
    "#### Formula\n",
    "\n",
    "The formula for R² is:\n",
    "\n",
    "$$\n",
    "\\displaystyle R^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ represents the actual values.\n",
    "- $\\hat{y}_i$ represents the predicted values.\n",
    "- $\\bar{y}$ is the mean of the actual values.\n",
    "- $n$ is the number of data points.\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "- **High R² Value**: Indicates that the model explains a large portion of the variance in the target variable, thus having better predictive power.\n",
    "- **Low R² Value**: Suggests that the model does not explain much of the variance in the target variable, indicating poor predictive performance.\n",
    "\n",
    "#### Why R² is Relevant\n",
    "\n",
    "In the context of the California housing dataset, using R² allows us to understand how well our model captures the underlying patterns in the housing prices. Given the complexity and variability in real estate prices, a high R² value would be an indication that our model is effective in predicting housing prices based on the given features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b963094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73bd52",
   "metadata": {},
   "source": [
    "### 5.3. Interpreting the Results\n",
    "\n",
    "The **Random Forest Regressor** achieved a Mean Squared Error (MSE) of `0.2555` and a Coefficient of Determination (R²) of `0.8050`. These results indicate that the Random Forest model is quite effective in predicting housing prices, as it explains `80.50%` of the variance in the target variable. The relatively low MSE value suggests that the differences between the predicted and actual prices are small, which signifies a high level of accuracy in the model's predictions.\n",
    "\n",
    "On the other hand, the **Gradient Boosting Regressor** resulted in a Mean Squared Error (MSE) of `0.2940` and a Coefficient of Determination (R²) of `0.7756`. While this model also performs well, explaining `77.56%` of the variance in the housing prices, its performance is slightly inferior to that of the Random Forest Regressor. \n",
    "\n",
    "The higher MSE value compared to the Random Forest model indicates that the Gradient Boosting model has larger prediction errors on average. \n",
    "\n",
    "Despite this, both models demonstrate strong predictive capabilities, making them valuable tools for estimating housing prices in the California market. The choice between the two models may depend on other factors such as interpretability, computational efficiency, or specific characteristics of the dataset\n",
    "\n",
    "\n",
    "### 5.4 Visualizing Results\n",
    "\n",
    "To better understand our results, we can visualizes the performance of the *Random Forest Regressor* (our best modek) by **plotting actual versus predicted housing prices**. The scatter plot shows individual data points with actual prices on the x-axis and predicted prices on the y-axis, while the dashed line represents a perfect prediction scenario where actual and predicted prices are equal. \n",
    "\n",
    "Points lying close to this line indicate accurate predictions, whereas points farther away signify larger prediction errors. This visualization is relevant because it allows us to easily assess how well the model's predictions align with actual values, highlighting the model's strengths and areas for improvement in predicting California housing prices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7b11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60577a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this project, we developed on an **end-to-end analysis and modeling of the California Housing dataset**. Beginning with data loading and preprocessing, we converted the dataset into a structured Pandas DataFrame, allowing for easy manipulation and analysis. Exploratory Data Analysis (EDA) followed, where we visualized the distribution of features, explored correlations using a heatmap, and identified key variables influencing housing prices.\n",
    "\n",
    "Subsequently, we prepared the data for modeling by standardizing numerical features and splitting the dataset into training and testing sets. We then employed two powerful regression algorithms, Random Forest and Gradient Boosting, to predict housing prices. Evaluation metrics such as Mean Squared Error (MSE) and Coefficient of Determination (R²) were used to assess model performance. The Random Forest model exhibited an MSE of `0.2555` and `R²` of `0.8050`, indicating strong predictive capability. Further, the Gradient Boosting model showed an MSE of `0.2940` and `R²` of `0.7756`, highlighting its robustness in predicting housing prices. Visualizations of model predictions against actual prices provided insights into model accuracy and highlighted areas for potential improvement. \n",
    "\n",
    "This project underscores the value of data-driven approaches in understanding complex real-world phenomena like housing markets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
