{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d811d2",
   "metadata": {},
   "source": [
    "<img src=\"../figs/holberton_logo.png\" alt=\"logo\" width=\"500\"/>\n",
    "\n",
    "# Week 1. Introduction to Machine Learning üöÄ\n",
    "\n",
    "## üõ≥Ô∏è Machine Learning Fundamentals with the Titanic Dataset\n",
    "\n",
    "Ever pondered if Jack could've made it out alive? \n",
    "\n",
    "Then, let's try to explore fundamentals of machine learning by building a simple model that can help us predict the survival of passengers in the famous Titanic ship. This project is best enjoyed with some [background music](https://www.youtube.com/watch?v=F2RnxZnubCM)\n",
    "\n",
    "\n",
    "Let's set sail! üè¥‚Äç‚ò†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11feaa8e",
   "metadata": {},
   "source": [
    "### Step 1: Load the Data üì¶\n",
    "\n",
    "First, we'll load the Titanic dataset using `Seaborn` and take a peek at what we're working with.\n",
    "We start by importing essential libraries: \n",
    "\n",
    "- `pandas` for data manipulation\n",
    "- `seaborn` for loading the Titanic dataset and visualization\n",
    "- `sklearn` for machine learning models and evaluation metrics\n",
    "- `matplotlib` for plotting. \n",
    "\n",
    "We then load the Titanic dataset using `Seaborn` and display its first few rows to understand the structure and contents of the data.\n",
    "\n",
    "The dataset contains `891` rows and `15` columns, where each column represents\n",
    "\n",
    "- `survived`: Indicates if the passenger survived (`1`) or not (`0`).\n",
    "- `pclass`: Passenger class (1st, 2nd, or 3rd class).\n",
    "- `sex`: Gender of the passenger (male or female).\n",
    "- `age`: Age of the passenger in years.\n",
    "- `sibsp`: Number of siblings or spouses aboard the Titanic.\n",
    "- `parch`: Number of parents or children aboard the Titanic.\n",
    "- `fare`: Fare paid by the passenger.\n",
    "- `embarked`: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton).\n",
    "- `class`: Passenger class (first, second, or third).\n",
    "- `who`: Gender classification (man, woman, child).\n",
    "- `adult_male`: Indicates if the passenger is an adult male (True) or not (False).\n",
    "- `deck`: Deck where the passenger was staying.\n",
    "- `embark_town`: Town where the passenger boarded the Titanic.\n",
    "- `alive`: Indicates if the passenger survived (yes) or not (no).\n",
    "- `alone`: Indicates if the passenger was alone (True) or not (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc62d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Titanic dataset\n",
    "\n",
    "# Display the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55bde55",
   "metadata": {},
   "source": [
    "### Step 2: Analyze and Preprocess the Data üîç\n",
    "\n",
    "#### Check for missing values\n",
    "\n",
    "We check for missing values using `titanic_df.isnull().sum()` to identify any gaps in our dataset that need to be addressed. **Missing values can lead to errors or biases** in our model, so it's crucial to detect and handle them before proceeding with analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b0218",
   "metadata": {},
   "source": [
    "The summary indicates the number of missing values in each column of the Titanic dataset. Critical columns like '`age`' and '`embarked`' have `177` and `2` missing values respectively, which need to be addressed. \n",
    "Columns like '`deck`' have a high number of missing values (`688`)\n",
    "\n",
    "#### Handle Missing Values\n",
    "\n",
    "To handle missing values, we \n",
    "\n",
    "- Fill the missing '`age`' values with the median, ensuring that the dataset remains representative without being skewed by outliers. \n",
    "- The '`embarked`' column's missing values are filled with the mode, the most common value, to maintain consistency. \n",
    "- We drop columns with excessive missing values or irrelevant data to simplify the dataset. \n",
    "- Categorical variables are converted to numerical ones to make them usable for machine learning algorithms. \n",
    "\n",
    "Finally, we check the cleaned data to ensure these preprocessing steps were applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e10619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'age' with the median\n",
    "\n",
    "# Fill missing values in 'embarked' with the mode\n",
    "\n",
    "# Drop columns we won't use for this model ('deck', 'embark_town', 'alive', 'class', 'who', 'adult_male', 'parch', 'sibsp')\n",
    "\n",
    "# Convert categorical variables to numerical ones ('embarked')\n",
    "\n",
    "# Check the cleaned data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9793823",
   "metadata": {},
   "source": [
    "### Step 3: Prepare for Train-Test Split üßπ\n",
    "\n",
    "By dividing the dataset into training and testing sets, we can **train the model on one subset** (training set) and **evaluate its performance on another subset** (testing set) that the model hasn't seen before. \n",
    "\n",
    "**This helps in assessing how well the model generalizes to new, unseen data.**\n",
    "\n",
    "Technically, we define our features (`X`) by dropping the target column '`survived`' from the dataset, and the target (`y`) as the 'survived' column. \n",
    "\n",
    "We then use `train_test_split` from `sklearn` to split the data into training and testing sets. Here, `80%` of the data is used for training, and `20%` is reserved for testing. The `random_state=42` ensures reproducibility of the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff791e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "\n",
    "# Split the data\n",
    "\n",
    "# Check the shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80734d",
   "metadata": {},
   "source": [
    "### Step 4: Apply Logistic Regression and Decision Tree üå≥\n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "##### How Logistic Regression Works:\n",
    "\n",
    "Logistic regression is a **statistical method for binary classification** that models the probability of a binary outcome based on one or more predictor variables. It uses the logistic function to convert linear combinations of features into a probability score between `0` and `1`. The model then applies a threshold (usually `0.5`) to decide the class label.\n",
    "\n",
    "#####  Why It Is Useful in This Context:\n",
    "\n",
    "In the context of the Titanic dataset, logistic regression is useful because it **provides a straightforward way to predict whether a passenger survived** (binary outcome: survived or not survived) based on features such as age, fare, sex, etc. Its interpretability and efficiency make it suitable for this binary classification task.\n",
    "\n",
    "##### What We Aim to Achieve:\n",
    "\n",
    "By training a logistic regression model, we aim to predict the survival of passengers based on their features, evaluate the model's accuracy, and understand the significance of different features in predicting survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "\n",
    "# Predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7bf94",
   "metadata": {},
   "source": [
    "#### Understand Feature Importance\n",
    "\n",
    "Visualizing feature importance in logistic regression helps us **understand which features have the most significant impact on the model's predictions**. By plotting the coefficients of the features, we can see the magnitude and direction of each feature's influence on the outcome (survival)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance for logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174b4f3",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "##### How Decision Tree Works:\n",
    "\n",
    "A decision tree is a machine learning algorithm used for both classification and regression tasks. It works by **splitting the dataset into subsets based on the value of input features**. This splitting is done recursively, creating branches until a decision node (leaf) is reached. **Each internal node represents a feature**, each **branch represents a decision rule**, and **each leaf node represents the outcome**.\n",
    "\n",
    "##### Why It Is Useful in This Context:\n",
    "\n",
    "In the context of the Titanic dataset, a decision tree is useful because it can capture complex interactions between features and is **easy to interpret**. It visually shows the decision-making process, which helps in understanding how different features contribute to the survival prediction.\n",
    "\n",
    "#####  What We Aim to Achieve:\n",
    "\n",
    "By training a decision tree model, we aim to predict the survival of passengers based on their features, evaluate the model's accuracy, and gain insights into the decision-making process of the model through visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af093b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree model\n",
    "\n",
    "# Predict on test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54544614",
   "metadata": {},
   "source": [
    "#### Visualize the Decision Tree üå≥üîç\n",
    "Time to visualize our decision tree and understand how our model behaves.\n",
    "\n",
    "Visualizing the decision tree provides a detailed look at how the model makes predictions. It shows the structure of the tree, including how the dataset is split at each node based on feature values, and the decisions made at each node\n",
    "\n",
    "This visualization provides a comprehensive view of the decision-making process of the tree model. It shows:\n",
    "\n",
    "- Which features are used for splitting the data at each node.\n",
    "- The conditions for these splits.\n",
    "- The class predictions at each leaf node.\n",
    "- The flow of decisions from the root to the leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c410b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "\n",
    "# Save the plot with high resolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cadbb",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate the Models üìä\n",
    "Time to see how our models performed! We'll use a confusion matrix to evaluate the results.\n",
    "\n",
    "#### Accuracy Score\n",
    "\n",
    "Accuracy is a metric used to evaluate the performance of a classification model. **It measures the proportion of correctly classified instances out of the total instances**. In the context of logistic regression, accuracy tells us how often the model correctly predicts the survival status of passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4442b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy for logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f1b74b",
   "metadata": {},
   "source": [
    "The accuracy score for logistic regression is approximately `0.799`. This means that the model correctly predicts the survival status of passengers about `79.9%` of the time.\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "We generate and visualize the confusion matrix for logistic regression to understand the model's performance in predicting survival outcomes.\n",
    "\n",
    "The confusion matrix provides a detailed breakdown of the model's predictions. It shows the number of true positives, true negatives, false positives, and false negatives, allowing us to evaluate the model's accuracy and identify any potential issues, such as misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for logistic regression\n",
    "\n",
    "# Plot confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433af39",
   "metadata": {},
   "source": [
    "The confusion matrix for logistic regression shows:\n",
    "    \n",
    "- **True Positives (TP)**: This refers to the number of instances where the model correctly predicted that a passenger survived (positive class) and the actual outcome was also survival. \n",
    "\n",
    "- **True Negatives (TN)**: This indicates the number of instances where the model correctly predicted that a passenger did not survive (negative class) and the actual outcome was also not survival. \n",
    "\n",
    "- **False Positives (FP)**: These are the instances where the model incorrectly predicted that a passenger survived (positive class), but the actual outcome was non-survival. \n",
    "\n",
    "- **False Negatives (FN)**: This represents the number of instances where the model incorrectly predicted that a passenger did not survive (negative class), but the actual outcome was survival. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5ce37",
   "metadata": {},
   "source": [
    "#### Accuracy Score and Confusion Matrix for Decision Tree\n",
    "\n",
    "Similarly, we compute the accuracy score for the decision tree model to assess its performance in predicting survival outcomes\n",
    "\n",
    "The accuracy score for the decision tree model is approximately `0.782`. This means that the decision tree model correctly predicts the survival status of passengers about `78.2%` of the time.\n",
    "\n",
    "When comparing the accuracy scores of the logistic regression and decision tree models, we observe a similar behavior, though strictly speaking the logistic regression model performs slightly better in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for decision tree\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df883c",
   "metadata": {},
   "source": [
    "### Conclusion üéâ\n",
    "\n",
    "And there you have it! We've navigated through the Titanic dataset, preprocessed it, and applied logistic regression and decision tree models to predict passenger survival. We also visualized our decision tree and saved it as a high-resolution image. Not only did we analyze our predictions with confusion matrices, but we also had a bit of fun along the way! üåäüõ≥Ô∏è\n",
    "\n",
    "Feel free to experiment further and explore more about model tuning and feature engineering. \n",
    "\n",
    "#### Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
